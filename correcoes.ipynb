{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import exit\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import dirname, join, isfile, isdir\n",
    "from os import makedirs\n",
    "from datetime import datetime, timedelta, date\n",
    "\n",
    "from bulletin.data.notifica import Notifica\n",
    "from bulletin.data.casos_confirmados import CasosConfirmados\n",
    "from bulletin.commom.utils import Timer, get_better_notifica\n",
    "from bulletin.commom.static import meses\n",
    "from bulletin.metabase.request import download_metabase\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "output = join(\"output\",\"correcoes\",\"notifica\")\n",
    "\n",
    "if not isdir(output):\n",
    "    makedirs(output)\n",
    "\n",
    "timerAll = Timer()\n",
    "timer = Timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "baixar_notifica = True if input(\"Enter para continuar, S para baixar notifica\") == 'S' else False\n",
    "ler_notifica = True if input(\"Enter para continuar, S para ler notifica\") == 'S' else False\n",
    "ler_casos = True if input(\"Enter para continuar, S para ler casos\") == 'S' else False\n",
    "dropar = True if input(\"Dropar duplicados\") == 'S' else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requesting classificacao_final IS NULL\n",
      "Success code 202\n",
      "Saving in input\\queries\\null.csv\n",
      "Download finish, time elapsed: 0:00:40.495070\n",
      "\n",
      "\n",
      "(533, 26)\n",
      "Requesting classificacao_final = 0\n",
      "Success code 202\n",
      "Saving in input\\queries\\0.csv\n",
      "Download finish, time elapsed: 0:00:16.521235\n",
      "\n",
      "\n",
      "(137, 26)\n",
      "Requesting classificacao_final = 1\n",
      "Deu ruim no 1, sleep 30 seconds\n",
      "Requesting classificacao_final = 1\n",
      "Deu ruim no 1, sleep 30 seconds\n",
      "Requesting classificacao_final = 1\n",
      "Deu ruim no 1, sleep 30 seconds\n",
      "Requesting classificacao_final = 1\n",
      "Success code 202\n",
      "Saving in input\\queries\\1.csv\n",
      "Deu ruim no 1, sleep 30 seconds\n",
      "Requesting classificacao_final = 1\n",
      "Deu ruim no 1, sleep 30 seconds\n",
      "Requesting classificacao_final = 1\n",
      "Deu ruim no 1, sleep 30 seconds\n",
      "Requesting classificacao_final = 1\n",
      "Deu ruim no 1, sleep 30 seconds\n",
      "Requesting classificacao_final = 1\n",
      "Deu ruim no 1, sleep 30 seconds\n",
      "Requesting classificacao_final = 1\n",
      "Success code 200\n",
      "Saving in input\\queries\\1.csv\n",
      "Download finish, time elapsed: 0:01:00.476789\n",
      "\n",
      "\n",
      "Deu ruim no 1, sleep 30 seconds\n",
      "Requesting classificacao_final = 1\n",
      "Deu ruim no 1, sleep 30 seconds\n",
      "Requesting classificacao_final = 1\n",
      "Deu ruim no 1, sleep 30 seconds\n",
      "Requesting classificacao_final = 1\n",
      "Success code 202\n",
      "Saving in input\\queries\\1.csv\n",
      "Deu ruim no 1, sleep 30 seconds\n",
      "Requesting classificacao_final = 1\n",
      "Success code 202\n",
      "Saving in input\\queries\\1.csv\n",
      "Deu ruim no 1, sleep 30 seconds\n",
      "Requesting classificacao_final = 1\n",
      "Deu ruim no 1, sleep 30 seconds\n",
      "Requesting classificacao_final = 1\n",
      "Deu ruim no 1, sleep 30 seconds\n",
      "Requesting classificacao_final = 1\n",
      "Deu ruim no 1, sleep 30 seconds\n",
      "Requesting classificacao_final = 1\n",
      "Deu ruim no 1, sleep 30 seconds\n",
      "Requesting classificacao_final = 1\n",
      "Deu ruim no 1, sleep 30 seconds\n",
      "Requesting classificacao_final = 1\n",
      "Deu ruim no 1, sleep 30 seconds\n",
      "Requesting classificacao_final = 1\n",
      "Success code 202\n",
      "Saving in input\\queries\\1.csv\n",
      "Download finish, time elapsed: 0:00:43.511349\n",
      "\n",
      "\n",
      "(923869, 26)\n",
      "Requesting classificacao_final = 2\n",
      "Success code 202\n",
      "Saving in input\\queries\\2.csv\n",
      "Download finish, time elapsed: 0:00:46.662524\n",
      "\n",
      "\n",
      "(648404, 26)\n",
      "Requesting classificacao_final = 3\n",
      "Success code 202\n",
      "Saving in input\\queries\\3.csv\n",
      "Deu ruim no 3, sleep 30 seconds\n",
      "Requesting classificacao_final = 3\n",
      "Deu ruim no 3, sleep 30 seconds\n",
      "Requesting classificacao_final = 3\n",
      "Success code 202\n",
      "Saving in input\\queries\\3.csv\n",
      "Download finish, time elapsed: 0:00:25.924865\n",
      "\n",
      "\n",
      "(954422, 26)\n",
      "Requesting classificacao_final = 5\n",
      "Success code 202\n",
      "Saving in input\\queries\\5.csv\n",
      "Download finish, time elapsed: 0:00:32.592917\n",
      "\n",
      "\n",
      "(7007, 26)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-fa859f83059a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mnotifica\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnotifica\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mcasos_confirmados\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCasosConfirmados\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\terc.vinicius\\covid19datascience\\bulletin\\data\\notifica.py\u001b[0m in \u001b[0;36mshape\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;31m#----------------------------------------------------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__source\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__source\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__source\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'evolucao'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__source\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__source\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'evolucao'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__source\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__source\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'evolucao'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__source\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__source\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'evolucao'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdownload_todas_notificacoes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "notifica = Notifica()\n",
    "if ler_notifica or baixar_notifica:\n",
    "    if baixar_notifica:\n",
    "        notifica.download_todas_notificacoes()\n",
    "    if ler_notifica:\n",
    "        notifica.read_todas_notificacoes()\n",
    "        notifica.save()\n",
    "else:\n",
    "    notifica.load()\n",
    "\n",
    "print(notifica.shape())\n",
    "\n",
    "casos_confirmados = CasosConfirmados()\n",
    "if ler_casos:\n",
    "    casos_confirmados.read()\n",
    "    casos_confirmados.save()\n",
    "else:\n",
    "    casos_confirmados.load()\n",
    "\n",
    "print(casos_confirmados.shape())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casosn = notifica.get_casos()\n",
    "casosn['duplicado'] = 0\n",
    "casosn['manter'] = 0\n",
    "casosc = casos_confirmados.get_casos()\n",
    "casosn.groupby('classificacao_final')[['id']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casos_duplicados = casosn.loc[(casosn['cpf'].notnull()) & (casosn.duplicated('cpf',keep=False))].sort_values('cpf')\n",
    "casosn.loc[casos_duplicados.index, 'duplicado'] = 1 \n",
    "\n",
    "print(f\"Total de pacientes com mais de uma ocorrencia: {len(casos_duplicados)}\")\n",
    "print(f\"{len(casos_duplicados.groupby('cpf'))} pacientes pelo CPF que estavam com mais de uma ocorrencia\")\n",
    "\n",
    "all_casos_duplicados = set()\n",
    "all_duplicados_mantidos = set()\n",
    "manter = []\n",
    "\n",
    "for hash, group in casos_duplicados.groupby('cpf'):\n",
    "    idx = get_better_notifica(group)\n",
    "    #check reinfection\n",
    "    manter.append(idx)\n",
    "\n",
    "\n",
    "casosn.loc[manter, 'manter'] = 1 \n",
    "\n",
    "casos_duplicados = set(casos_duplicados.index.tolist())\n",
    "casos_duplicados = casos_duplicados - set(manter)\n",
    "\n",
    "all_duplicados_mantidos |= set(manter)\n",
    "all_casos_duplicados |= casos_duplicados\n",
    "casosn.loc[casos_duplicados].to_csv(join(output,'pacientes_duplicados_cpf.csv'), index=False)\n",
    "\n",
    "casosn.loc[casos_duplicados].groupby('classificacao_final')[['id']].count()\n",
    "if dropar:\n",
    "    casosn = casosn.drop(index=casos_duplicados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casos_duplicados = casosn.loc[(casosn['nome_mae'].notnull()) & (casosn.duplicated('hash_mae',keep=False))].sort_values('nome_mae')\n",
    "casosn.loc[casos_duplicados.index, 'duplicado'] = 1 \n",
    "\n",
    "print(f\"Total de pacientes com mais de uma ocorrencia pelo nome+nome_mae: {len(casos_duplicados)}\")\n",
    "print(f\"{len(casos_duplicados.groupby('nome_mae'))} pacientes pelo nome+nome_mae que estavam com mais de uma ocorrencia\")\n",
    "\n",
    "manter = []\n",
    "for hash, group in casos_duplicados.groupby('nome_mae'):\n",
    "    idx = get_better_notifica(group)\n",
    "    manter.append(idx)\n",
    "\n",
    "casosn.loc[manter, 'manter'] = 1 \n",
    "\n",
    "casos_duplicados = set(casos_duplicados.index.tolist())\n",
    "casos_duplicados = casos_duplicados - set(manter)\n",
    "\n",
    "all_duplicados_mantidos |= set(manter)\n",
    "all_casos_duplicados |= casos_duplicados\n",
    "casosn.loc[casos_duplicados].to_csv(join(output,'pacientes_duplicados_nome_mae.csv'), index=False)\n",
    "\n",
    "casosn.loc[casos_duplicados].groupby('classificacao_final')[['id']].count()\n",
    "if dropar:\n",
    "    casosn = casosn.drop(index=casos_duplicados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casos_duplicados = casosn.loc[(casosn['hash_nasc'].notnull()) & (casosn.duplicated('hash_nasc',keep=False))].sort_values('data_nascimento')\n",
    "casosn.loc[casos_duplicados.index, 'duplicado'] = 1 \n",
    "\n",
    "print(f\"Total de pacientes com mais de uma ocorrencia pelo data_nascimento: {len(casos_duplicados)}\")\n",
    "print(f\"{len(casos_duplicados.groupby('hash_nasc'))} pacientes pelo data_nascimento que estavam com mais de uma ocorrencia\")\n",
    "\n",
    "manter = []\n",
    "for hash, group in casos_duplicados.groupby('hash_nasc'):\n",
    "    idx = get_better_notifica(group)\n",
    "    manter.append(idx)\n",
    "\n",
    "casosn.loc[manter, 'manter'] = 1 \n",
    "\n",
    "casos_duplicados = set(casos_duplicados.index.tolist())\n",
    "casos_duplicados = casos_duplicados - set(manter)\n",
    "\n",
    "all_duplicados_mantidos |= set(manter)\n",
    "all_casos_duplicados |= casos_duplicados\n",
    "casosn.loc[casos_duplicados].to_csv(join(output,'pacientes_duplicados_data_nascimento.csv'), index=False)\n",
    "\n",
    "casosn.loc[casos_duplicados].groupby('classificacao_final')[['id']].count()\n",
    "if dropar:\n",
    "    casosn = casosn.drop(index=casos_duplicados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casos_duplicados = casosn.loc[(casosn['hash_resid'].notnull()) & (casosn.duplicated('hash_resid',keep=False))].sort_values('paciente')\n",
    "casosn.loc[casos_duplicados.index, 'duplicado'] = 1 \n",
    "\n",
    "print(f\"Total de pacientes com mais de uma ocorrencia pelo hash_resid: {len(casos_duplicados)}\")\n",
    "print(f\"{len(casos_duplicados.groupby('hash_resid'))} pacientes pelo hash_resid que estavam com mais de uma ocorrencia\")\n",
    "\n",
    "manter = []\n",
    "for hash, group in casos_duplicados.groupby('hash_resid'):\n",
    "    idx = get_better_notifica(group)\n",
    "    manter.append(idx)\n",
    "\n",
    "casosn.loc[manter, 'manter'] = 1 \n",
    "\n",
    "casos_duplicados = set(casos_duplicados.index.tolist())\n",
    "casos_duplicados = casos_duplicados - set(manter)\n",
    "\n",
    "all_duplicados_mantidos |= set(manter)\n",
    "all_casos_duplicados |= casos_duplicados\n",
    "casosn.loc[casos_duplicados].to_csv(join(output,'pacientes_duplicados_nome_idade_mun_resid.csv'), index=False)\n",
    "\n",
    "casosn.loc[casos_duplicados].groupby('classificacao_final')[['id']].count()\n",
    "if dropar:\n",
    "    casosn = casosn.drop(index=casos_duplicados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casos_duplicados = casosn.loc[(casosn['hash_atend'].notnull()) & (casosn.duplicated('hash_atend',keep=False))].sort_values('paciente')\n",
    "casosn.loc[casos_duplicados.index, 'duplicado'] = 1 \n",
    "\n",
    "print(f\"Total de pacientes com mais de uma ocorrencia pelo hash_atend: {len(casos_duplicados)}\")\n",
    "print(f\"{len(casos_duplicados.groupby('hash_atend'))} pacientes pelo hash_atend que estavam com mais de uma ocorrencia\")\n",
    "\n",
    "manter = []\n",
    "for hash, group in casos_duplicados.groupby('hash_atend'):\n",
    "    idx = get_better_notifica(group)\n",
    "    manter.append(idx)\n",
    "\n",
    "casosn.loc[manter, 'manter'] = 1 \n",
    "\n",
    "casos_duplicados = set(casos_duplicados.index.tolist())\n",
    "casos_duplicados = casos_duplicados - set(manter)\n",
    "\n",
    "all_duplicados_mantidos |= set(manter)\n",
    "all_casos_duplicados |= casos_duplicados\n",
    "casosn.loc[casos_duplicados].to_csv(join(output,'pacientes_duplicados_nome_idade_mun_atend.csv'), index=False)\n",
    "\n",
    "casosn.loc[casos_duplicados].groupby('classificacao_final')[['id']].count()\n",
    "if dropar:\n",
    "    casosn = casosn.drop(index=casos_duplicados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casos_duplicados = casosn.loc[(casosn['hash_diag'].notnull()) & (casosn.duplicated('hash_diag',keep=False))].sort_values('paciente')\n",
    "casosn.loc[casos_duplicados.index, 'duplicado'] = 1 \n",
    "\n",
    "print(f\"Total de pacientes com mais de uma ocorrencia pelo hash_diag: {len(casos_duplicados)}\")\n",
    "print(f\"{len(casos_duplicados.groupby('hash_diag'))} pacientes pelo hash_diag que estavam com mais de uma ocorrencia\")\n",
    "\n",
    "manter = []\n",
    "for hash, group in casos_duplicados.groupby('hash_diag'):\n",
    "    idx = get_better_notifica(group)\n",
    "    manter.append(idx)\n",
    "\n",
    "casosn.loc[manter, 'manter'] = 1 \n",
    "\n",
    "casos_duplicados = set(casos_duplicados.index.tolist())\n",
    "casos_duplicados = casos_duplicados - set(manter)\n",
    "\n",
    "all_duplicados_mantidos |= set(manter)\n",
    "all_casos_duplicados |= casos_duplicados\n",
    "casosn.loc[casos_duplicados].to_csv(join(output,'pacientes_duplicados_hash_diag.csv'), index=False)\n",
    "\n",
    "casosn.loc[casos_duplicados].groupby('classificacao_final')[['id']].count()\n",
    "if dropar:\n",
    "    casosn = casosn.drop(index=casos_duplicados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notifica.save(casosn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}