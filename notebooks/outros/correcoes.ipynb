{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sys import exit, stderr, stdin, stdout\n",
    "from time import sleep\n",
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "from os.path import dirname, join, isfile, isdir\n",
    "from os import makedirs\n",
    "import subprocess\n",
    "from datetime import datetime, timedelta, date\n",
    "\n",
    "from bulletin.notifica import Notifica\n",
    "from bulletin.utils.utils import Timer, get_better_notifica\n",
    "from bulletin.utils.normalize import normalize_hash\n",
    "from bulletin.utils.static import meses\n",
    "from bulletin.metabase.request import download_metabase\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "output = join(\"output\",\"correcoes\",\"notifica\")\n",
    "\n",
    "if not isdir(output):\n",
    "    makedirs(output)\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "timerAll = Timer()\n",
    "timer = Timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baixar_notifica = False#True if input(\"Enter para continuar, S para baixar notifica\") == 'S' else False\n",
    "ler_notifica = False#True if input(\"Enter para continuar, S para ler notifica\") == 'S' else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "notifica = Notifica()\n",
    "if ler_notifica or baixar_notifica:\n",
    "    if baixar_notifica:\n",
    "        notifica.download_todas_notificacoes()\n",
    "    if ler_notifica:\n",
    "        notifica.read_todas_notificacoes()\n",
    "        notifica.save()\n",
    "else:\n",
    "    notifica.load()\n",
    "\n",
    "print(notifica.shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casosn = notifica.get_casos()\n",
    "# casosn = casosn.loc[(casosn['mun_resid']=='CURITIBA') & (casosn['classificacao_final']==2)]\n",
    "casosn.groupby('classificacao_final')[['id']].count().append(pd.DataFrame(index=['total'],columns=['id'],data=[len(casosn)])).to_csv('classificacao_final_count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.start()\n",
    "\n",
    "pacientes = { 'pacientes': casosn['paciente'].apply(normalize_hash).values.tolist() }\n",
    "with open('pacientes.json', 'w') as json_file:\n",
    "  json.dump(pacientes, json_file)\n",
    "\n",
    "subprocess.call((\"node\", 'soundex.js'))\n",
    "\n",
    "with open('pacientes_soundex.json', 'r') as json_file:\n",
    "  pacientes = json.load(json_file)\n",
    "\n",
    "casosn['soundex'] = pacientes\n",
    "casosn = casosn.sort_values('soundex')\n",
    "\n",
    "timer.stop()\n",
    "print('soundex: ',timer.ftime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.start()\n",
    "\n",
    "keys = ['soundex','paciente','idade','ibge_unidade_notifica','ibge_residencia','data_nascimento','nome_mae','cpf','id']\n",
    "\n",
    "casosn_hash = casosn[keys+['status_notificacao','classificacao_final','metodo','evolucao']]\n",
    "casos_agrupados = casosn_hash.sort_values('soundex').groupby(keys[:-1])\n",
    "casos_agrupados_count = casos_agrupados[['id']].count().rename(columns={'id':'count'}).sort_values('count', ascending=False)\n",
    "casos_agrupados_count.to_csv('casos_agrupados_count.csv')\n",
    "\n",
    "timer.stop()\n",
    "print('casos_agrupados_count: ',timer.ftime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.start()\n",
    "\n",
    "pacientes = pd.DataFrame(index=casos_agrupados_count.index,columns=['ids','status_notificacao','classificacao_final','metodo','evolucao'], data=[])\n",
    "\n",
    "for idx,df in casos_agrupados:\n",
    "    pacientes.loc[idx,'ids'] = [ x for x in df['id'].values ]\n",
    "    pacientes.loc[idx,'status_notificacao'] = [ x for x in df['status_notificacao'].values ]\n",
    "    pacientes.loc[idx,'classificacao_final'] = [ x for x in df['classificacao_final'].values ]\n",
    "    pacientes.loc[idx,'metodo'] = [ x for x in df['metodo'].values ]\n",
    "    pacientes.loc[idx,'evolucao'] = [ x for x in df['evolucao'].values ]\n",
    "\n",
    "pacientes.to_csv('pacientes.csv')\n",
    "timer.stop()\n",
    "print(f'pacientes ({len(pacientes)}): ',timer.ftime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.start()\n",
    "\n",
    "pacientes_duplicados = pacientes.loc[ [True if len(ids) > 1 else False for ids in pacientes['ids']]]\n",
    "pacientes_duplicados.to_csv('pacientes_duplicados.csv')\n",
    "\n",
    "timer.stop()\n",
    "print(f'pacientes_duplicados ({len(pacientes_duplicados)}): ',timer.ftime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exit()\n",
    "casos_duplicados = casosn.loc[(casosn['cpf'].notnull()) & (casosn.duplicated('cpf',keep=False))].sort_values('cpf')\n",
    "casosn.loc[casos_duplicados.index, 'duplicado'] = 1 \n",
    "\n",
    "print(f\"Total de pacientes com mais de uma ocorrencia: {len(casos_duplicados)}\")\n",
    "print(f\"{len(casos_duplicados.groupby('cpf'))} pacientes pelo CPF que estavam com mais de uma ocorrencia\")\n",
    "\n",
    "all_casos_duplicados = set()\n",
    "all_duplicados_mantidos = set()\n",
    "manter = []\n",
    "\n",
    "for hash, group in casos_duplicados.groupby('cpf'):\n",
    "    idx = get_better_notifica(group)\n",
    "    #check reinfection\n",
    "    manter.append(idx)\n",
    "\n",
    "\n",
    "casosn.loc[manter, 'manter'] = 1 \n",
    "\n",
    "casos_duplicados = set(casos_duplicados.index.tolist())\n",
    "casos_duplicados = casos_duplicados - set(manter)\n",
    "\n",
    "all_duplicados_mantidos |= set(manter)\n",
    "all_casos_duplicados |= casos_duplicados\n",
    "casosn.loc[casos_duplicados].to_csv(join(output,'pacientes_duplicados_cpf.csv'), index=False)\n",
    "\n",
    "casosn.loc[casos_duplicados].groupby('classificacao_final')[['id']].count()\n",
    "if dropar:\n",
    "    casosn = casosn.drop(index=casos_duplicados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casos_duplicados = casosn.loc[(casosn['nome_mae'].notnull()) & (casosn.duplicated('hash_mae',keep=False))].sort_values('nome_mae')\n",
    "casosn.loc[casos_duplicados.index, 'duplicado'] = 1 \n",
    "\n",
    "print(f\"Total de pacientes com mais de uma ocorrencia pelo nome+nome_mae: {len(casos_duplicados)}\")\n",
    "print(f\"{len(casos_duplicados.groupby('nome_mae'))} pacientes pelo nome+nome_mae que estavam com mais de uma ocorrencia\")\n",
    "\n",
    "manter = []\n",
    "for hash, group in casos_duplicados.groupby('nome_mae'):\n",
    "    idx = get_better_notifica(group)\n",
    "    manter.append(idx)\n",
    "\n",
    "casosn.loc[manter, 'manter'] = 1 \n",
    "\n",
    "casos_duplicados = set(casos_duplicados.index.tolist())\n",
    "casos_duplicados = casos_duplicados - set(manter)\n",
    "\n",
    "all_duplicados_mantidos |= set(manter)\n",
    "all_casos_duplicados |= casos_duplicados\n",
    "casosn.loc[casos_duplicados].to_csv(join(output,'pacientes_duplicados_nome_mae.csv'), index=False)\n",
    "\n",
    "casosn.loc[casos_duplicados].groupby('classificacao_final')[['id']].count()\n",
    "if dropar:\n",
    "    casosn = casosn.drop(index=casos_duplicados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casos_duplicados = casosn.loc[(casosn['hash_nasc'].notnull()) & (casosn.duplicated('hash_nasc',keep=False))].sort_values('data_nascimento')\n",
    "casosn.loc[casos_duplicados.index, 'duplicado'] = 1 \n",
    "\n",
    "print(f\"Total de pacientes com mais de uma ocorrencia pelo data_nascimento: {len(casos_duplicados)}\")\n",
    "print(f\"{len(casos_duplicados.groupby('hash_nasc'))} pacientes pelo data_nascimento que estavam com mais de uma ocorrencia\")\n",
    "\n",
    "manter = []\n",
    "for hash, group in casos_duplicados.groupby('hash_nasc'):\n",
    "    idx = get_better_notifica(group)\n",
    "    manter.append(idx)\n",
    "\n",
    "casosn.loc[manter, 'manter'] = 1 \n",
    "\n",
    "casos_duplicados = set(casos_duplicados.index.tolist())\n",
    "casos_duplicados = casos_duplicados - set(manter)\n",
    "\n",
    "all_duplicados_mantidos |= set(manter)\n",
    "all_casos_duplicados |= casos_duplicados\n",
    "casosn.loc[casos_duplicados].to_csv(join(output,'pacientes_duplicados_data_nascimento.csv'), index=False)\n",
    "\n",
    "casosn.loc[casos_duplicados].groupby('classificacao_final')[['id']].count()\n",
    "if dropar:\n",
    "    casosn = casosn.drop(index=casos_duplicados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casos_duplicados = casosn.loc[(casosn['hash_resid'].notnull()) & (casosn.duplicated('hash_resid',keep=False))].sort_values('paciente')\n",
    "casosn.loc[casos_duplicados.index, 'duplicado'] = 1 \n",
    "\n",
    "print(f\"Total de pacientes com mais de uma ocorrencia pelo hash_resid: {len(casos_duplicados)}\")\n",
    "print(f\"{len(casos_duplicados.groupby('hash_resid'))} pacientes pelo hash_resid que estavam com mais de uma ocorrencia\")\n",
    "\n",
    "manter = []\n",
    "for hash, group in casos_duplicados.groupby('hash_resid'):\n",
    "    idx = get_better_notifica(group)\n",
    "    manter.append(idx)\n",
    "\n",
    "casosn.loc[manter, 'manter'] = 1 \n",
    "\n",
    "casos_duplicados = set(casos_duplicados.index.tolist())\n",
    "casos_duplicados = casos_duplicados - set(manter)\n",
    "\n",
    "all_duplicados_mantidos |= set(manter)\n",
    "all_casos_duplicados |= casos_duplicados\n",
    "casosn.loc[casos_duplicados].to_csv(join(output,'pacientes_duplicados_nome_idade_mun_resid.csv'), index=False)\n",
    "\n",
    "casosn.loc[casos_duplicados].groupby('classificacao_final')[['id']].count()\n",
    "if dropar:\n",
    "    casosn = casosn.drop(index=casos_duplicados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casos_duplicados = casosn.loc[(casosn['hash_atend'].notnull()) & (casosn.duplicated('hash_atend',keep=False))].sort_values('paciente')\n",
    "casosn.loc[casos_duplicados.index, 'duplicado'] = 1 \n",
    "\n",
    "print(f\"Total de pacientes com mais de uma ocorrencia pelo hash_atend: {len(casos_duplicados)}\")\n",
    "print(f\"{len(casos_duplicados.groupby('hash_atend'))} pacientes pelo hash_atend que estavam com mais de uma ocorrencia\")\n",
    "\n",
    "manter = []\n",
    "for hash, group in casos_duplicados.groupby('hash_atend'):\n",
    "    idx = get_better_notifica(group)\n",
    "    manter.append(idx)\n",
    "\n",
    "casosn.loc[manter, 'manter'] = 1 \n",
    "\n",
    "casos_duplicados = set(casos_duplicados.index.tolist())\n",
    "casos_duplicados = casos_duplicados - set(manter)\n",
    "\n",
    "all_duplicados_mantidos |= set(manter)\n",
    "all_casos_duplicados |= casos_duplicados\n",
    "casosn.loc[casos_duplicados].to_csv(join(output,'pacientes_duplicados_nome_idade_mun_atend.csv'), index=False)\n",
    "\n",
    "casosn.loc[casos_duplicados].groupby('classificacao_final')[['id']].count()\n",
    "if dropar:\n",
    "    casosn = casosn.drop(index=casos_duplicados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casos_duplicados = casosn.loc[(casosn['hash_diag'].notnull()) & (casosn.duplicated('hash_diag',keep=False))].sort_values('paciente')\n",
    "casosn.loc[casos_duplicados.index, 'duplicado'] = 1 \n",
    "\n",
    "print(f\"Total de pacientes com mais de uma ocorrencia pelo hash_diag: {len(casos_duplicados)}\")\n",
    "print(f\"{len(casos_duplicados.groupby('hash_diag'))} pacientes pelo hash_diag que estavam com mais de uma ocorrencia\")\n",
    "\n",
    "manter = []\n",
    "for hash, group in casos_duplicados.groupby('hash_diag'):\n",
    "    idx = get_better_notifica(group)\n",
    "    manter.append(idx)\n",
    "\n",
    "casosn.loc[manter, 'manter'] = 1 \n",
    "\n",
    "casos_duplicados = set(casos_duplicados.index.tolist())\n",
    "casos_duplicados = casos_duplicados - set(manter)\n",
    "\n",
    "all_duplicados_mantidos |= set(manter)\n",
    "all_casos_duplicados |= casos_duplicados\n",
    "casosn.loc[casos_duplicados].to_csv(join(output,'pacientes_duplicados_hash_diag.csv'), index=False)\n",
    "\n",
    "casosn.loc[casos_duplicados].groupby('classificacao_final')[['id']].count()\n",
    "if dropar:\n",
    "    casosn = casosn.drop(index=casos_duplicados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notifica.save(casosn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
