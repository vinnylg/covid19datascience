{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import exit\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import dirname, join, isfile, isdir\n",
    "from os import makedirs\n",
    "from datetime import datetime, timedelta, date\n",
    "\n",
    "from bulletin.notifica import Notifica\n",
    "from bulletin.casos_confirmados import CasosConfirmados\n",
    "from bulletin.utils.utils import Timer, get_better_notifica\n",
    "from bulletin.utils.static import meses\n",
    "from bulletin.metabase.request import download_metabase\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "output = join(\"output\",\"correcoes\",\"notifica\")\n",
    "\n",
    "if not isdir(output):\n",
    "    makedirs(output)\n",
    "\n",
    "timerAll = Timer()\n",
    "timer = Timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baixar_notifica = True if input(\"Enter para continuar, S para baixar notifica\") == 'S' else False\n",
    "ler_notifica = True if input(\"Enter para continuar, S para ler notifica\") == 'S' else False\n",
    "ler_casos = True if input(\"Enter para continuar, S para ler casos\") == 'S' else False\n",
    "dropar = True if input(\"Dropar duplicados\") == 'S' else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "notifica = Notifica()\n",
    "if ler_notifica or baixar_notifica:\n",
    "    if baixar_notifica:\n",
    "        notifica.download_todas_notificacoes()\n",
    "    if ler_notifica:\n",
    "        notifica.read_todas_notificacoes()\n",
    "        notifica.save()\n",
    "else:\n",
    "    notifica.load()\n",
    "\n",
    "print(notifica.shape())\n",
    "\n",
    "casos_confirmados = CasosConfirmados()\n",
    "if ler_casos:\n",
    "    casos_confirmados.read()\n",
    "    casos_confirmados.save()\n",
    "else:\n",
    "    casos_confirmados.load()\n",
    "\n",
    "print(casos_confirmados.shape())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casosn = notifica.get_casos()\n",
    "casosn['duplicado'] = 0\n",
    "casosn['manter'] = 0\n",
    "casosc = casos_confirmados.get_casos()\n",
    "casosn.groupby('classificacao_final')[['id']].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casos_duplicados = casosn.loc[(casosn['cpf'].notnull()) & (casosn.duplicated('cpf',keep=False))].sort_values('cpf')\n",
    "casosn.loc[casos_duplicados.index, 'duplicado'] = 1 \n",
    "\n",
    "print(f\"Total de pacientes com mais de uma ocorrencia: {len(casos_duplicados)}\")\n",
    "print(f\"{len(casos_duplicados.groupby('cpf'))} pacientes pelo CPF que estavam com mais de uma ocorrencia\")\n",
    "\n",
    "all_casos_duplicados = set()\n",
    "all_duplicados_mantidos = set()\n",
    "manter = []\n",
    "\n",
    "for hash, group in casos_duplicados.groupby('cpf'):\n",
    "    idx = get_better_notifica(group)\n",
    "    #check reinfection\n",
    "    manter.append(idx)\n",
    "\n",
    "\n",
    "casosn.loc[manter, 'manter'] = 1 \n",
    "\n",
    "casos_duplicados = set(casos_duplicados.index.tolist())\n",
    "casos_duplicados = casos_duplicados - set(manter)\n",
    "\n",
    "all_duplicados_mantidos |= set(manter)\n",
    "all_casos_duplicados |= casos_duplicados\n",
    "casosn.loc[casos_duplicados].to_csv(join(output,'pacientes_duplicados_cpf.csv'), index=False)\n",
    "\n",
    "casosn.loc[casos_duplicados].groupby('classificacao_final')[['id']].count()\n",
    "if dropar:\n",
    "    casosn = casosn.drop(index=casos_duplicados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casos_duplicados = casosn.loc[(casosn['nome_mae'].notnull()) & (casosn.duplicated('hash_mae',keep=False))].sort_values('nome_mae')\n",
    "casosn.loc[casos_duplicados.index, 'duplicado'] = 1 \n",
    "\n",
    "print(f\"Total de pacientes com mais de uma ocorrencia pelo nome+nome_mae: {len(casos_duplicados)}\")\n",
    "print(f\"{len(casos_duplicados.groupby('nome_mae'))} pacientes pelo nome+nome_mae que estavam com mais de uma ocorrencia\")\n",
    "\n",
    "manter = []\n",
    "for hash, group in casos_duplicados.groupby('nome_mae'):\n",
    "    idx = get_better_notifica(group)\n",
    "    manter.append(idx)\n",
    "\n",
    "casosn.loc[manter, 'manter'] = 1 \n",
    "\n",
    "casos_duplicados = set(casos_duplicados.index.tolist())\n",
    "casos_duplicados = casos_duplicados - set(manter)\n",
    "\n",
    "all_duplicados_mantidos |= set(manter)\n",
    "all_casos_duplicados |= casos_duplicados\n",
    "casosn.loc[casos_duplicados].to_csv(join(output,'pacientes_duplicados_nome_mae.csv'), index=False)\n",
    "\n",
    "casosn.loc[casos_duplicados].groupby('classificacao_final')[['id']].count()\n",
    "if dropar:\n",
    "    casosn = casosn.drop(index=casos_duplicados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casos_duplicados = casosn.loc[(casosn['hash_nasc'].notnull()) & (casosn.duplicated('hash_nasc',keep=False))].sort_values('data_nascimento')\n",
    "casosn.loc[casos_duplicados.index, 'duplicado'] = 1 \n",
    "\n",
    "print(f\"Total de pacientes com mais de uma ocorrencia pelo data_nascimento: {len(casos_duplicados)}\")\n",
    "print(f\"{len(casos_duplicados.groupby('hash_nasc'))} pacientes pelo data_nascimento que estavam com mais de uma ocorrencia\")\n",
    "\n",
    "manter = []\n",
    "for hash, group in casos_duplicados.groupby('hash_nasc'):\n",
    "    idx = get_better_notifica(group)\n",
    "    manter.append(idx)\n",
    "\n",
    "casosn.loc[manter, 'manter'] = 1 \n",
    "\n",
    "casos_duplicados = set(casos_duplicados.index.tolist())\n",
    "casos_duplicados = casos_duplicados - set(manter)\n",
    "\n",
    "all_duplicados_mantidos |= set(manter)\n",
    "all_casos_duplicados |= casos_duplicados\n",
    "casosn.loc[casos_duplicados].to_csv(join(output,'pacientes_duplicados_data_nascimento.csv'), index=False)\n",
    "\n",
    "casosn.loc[casos_duplicados].groupby('classificacao_final')[['id']].count()\n",
    "if dropar:\n",
    "    casosn = casosn.drop(index=casos_duplicados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casos_duplicados = casosn.loc[(casosn['hash_resid'].notnull()) & (casosn.duplicated('hash_resid',keep=False))].sort_values('paciente')\n",
    "casosn.loc[casos_duplicados.index, 'duplicado'] = 1 \n",
    "\n",
    "print(f\"Total de pacientes com mais de uma ocorrencia pelo hash_resid: {len(casos_duplicados)}\")\n",
    "print(f\"{len(casos_duplicados.groupby('hash_resid'))} pacientes pelo hash_resid que estavam com mais de uma ocorrencia\")\n",
    "\n",
    "manter = []\n",
    "for hash, group in casos_duplicados.groupby('hash_resid'):\n",
    "    idx = get_better_notifica(group)\n",
    "    manter.append(idx)\n",
    "\n",
    "casosn.loc[manter, 'manter'] = 1 \n",
    "\n",
    "casos_duplicados = set(casos_duplicados.index.tolist())\n",
    "casos_duplicados = casos_duplicados - set(manter)\n",
    "\n",
    "all_duplicados_mantidos |= set(manter)\n",
    "all_casos_duplicados |= casos_duplicados\n",
    "casosn.loc[casos_duplicados].to_csv(join(output,'pacientes_duplicados_nome_idade_mun_resid.csv'), index=False)\n",
    "\n",
    "casosn.loc[casos_duplicados].groupby('classificacao_final')[['id']].count()\n",
    "if dropar:\n",
    "    casosn = casosn.drop(index=casos_duplicados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casos_duplicados = casosn.loc[(casosn['hash_atend'].notnull()) & (casosn.duplicated('hash_atend',keep=False))].sort_values('paciente')\n",
    "casosn.loc[casos_duplicados.index, 'duplicado'] = 1 \n",
    "\n",
    "print(f\"Total de pacientes com mais de uma ocorrencia pelo hash_atend: {len(casos_duplicados)}\")\n",
    "print(f\"{len(casos_duplicados.groupby('hash_atend'))} pacientes pelo hash_atend que estavam com mais de uma ocorrencia\")\n",
    "\n",
    "manter = []\n",
    "for hash, group in casos_duplicados.groupby('hash_atend'):\n",
    "    idx = get_better_notifica(group)\n",
    "    manter.append(idx)\n",
    "\n",
    "casosn.loc[manter, 'manter'] = 1 \n",
    "\n",
    "casos_duplicados = set(casos_duplicados.index.tolist())\n",
    "casos_duplicados = casos_duplicados - set(manter)\n",
    "\n",
    "all_duplicados_mantidos |= set(manter)\n",
    "all_casos_duplicados |= casos_duplicados\n",
    "casosn.loc[casos_duplicados].to_csv(join(output,'pacientes_duplicados_nome_idade_mun_atend.csv'), index=False)\n",
    "\n",
    "casosn.loc[casos_duplicados].groupby('classificacao_final')[['id']].count()\n",
    "if dropar:\n",
    "    casosn = casosn.drop(index=casos_duplicados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "casos_duplicados = casosn.loc[(casosn['hash_diag'].notnull()) & (casosn.duplicated('hash_diag',keep=False))].sort_values('paciente')\n",
    "casosn.loc[casos_duplicados.index, 'duplicado'] = 1 \n",
    "\n",
    "print(f\"Total de pacientes com mais de uma ocorrencia pelo hash_diag: {len(casos_duplicados)}\")\n",
    "print(f\"{len(casos_duplicados.groupby('hash_diag'))} pacientes pelo hash_diag que estavam com mais de uma ocorrencia\")\n",
    "\n",
    "manter = []\n",
    "for hash, group in casos_duplicados.groupby('hash_diag'):\n",
    "    idx = get_better_notifica(group)\n",
    "    manter.append(idx)\n",
    "\n",
    "casosn.loc[manter, 'manter'] = 1 \n",
    "\n",
    "casos_duplicados = set(casos_duplicados.index.tolist())\n",
    "casos_duplicados = casos_duplicados - set(manter)\n",
    "\n",
    "all_duplicados_mantidos |= set(manter)\n",
    "all_casos_duplicados |= casos_duplicados\n",
    "casosn.loc[casos_duplicados].to_csv(join(output,'pacientes_duplicados_hash_diag.csv'), index=False)\n",
    "\n",
    "casosn.loc[casos_duplicados].groupby('classificacao_final')[['id']].count()\n",
    "if dropar:\n",
    "    casosn = casosn.drop(index=casos_duplicados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notifica.save(casosn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
